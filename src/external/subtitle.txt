WEBVTT
Kind: captions
Language: en

00:00:06.720 --> 00:00:12.180
Welcome to the File Tree Walking Challenge.
In the last couple of videos, I've shown you

00:00:12.180 --> 00:00:16.080
a lot of ways to navigate the file tree,
with the many different methods on Files.

00:00:17.040 --> 00:00:20.700
These include:
Files.list; Files.walk;

00:00:20.700 --> 00:00:28.020
Files.find . These three methods return a
Stream of Paths. Files.newDirectoryStream.

00:00:29.100 --> 00:00:34.320
This method returns a DirectoryStream instance,
an iterable class, that's only one level deep,

00:00:34.320 --> 00:00:40.680
but is more efficient than creating a stream.
and Files.walkFileTree, which you've seen,

00:00:40.680 --> 00:00:45.360
can be more complex to use, but provides
hooks into the process which can be leveraged.

00:00:46.320 --> 00:00:51.420
In the last video, I used the sum of the file
sizes, to determine the size of a directory,

00:00:51.420 --> 00:00:55.020
and accumulated those sizes
up, to the parent directories.

00:00:55.980 --> 00:00:58.500
In this challenge, I want you
to do something very similar.

00:00:59.400 --> 00:01:01.500
In addition to summing up directory sizes,

00:01:01.500 --> 00:01:04.320
I want you to summarize the
number of Files in a directory.

00:01:05.280 --> 00:01:08.520
For a bonus, include the summary
of the number of subfolders.

00:01:09.480 --> 00:01:12.120
These numbers should include
nested files or folders.

00:01:13.860 --> 00:01:18.840
If you're on windows, you might be familiar with
the properties feature, in the File Explorer.

00:01:19.620 --> 00:01:21.420
I'm showing a screenshot on this slide.

00:01:22.440 --> 00:01:26.040
You can see the Size, which is the
cumulative size of all the files.

00:01:27.000 --> 00:01:30.900
You also can see that this folder
contains 17 files and 9 Folders in total.

00:01:32.040 --> 00:01:36.480
This folder count doesn't include the current
folder, but does include nested folders.

00:01:37.500 --> 00:01:42.180
You're welcome to use the walkFileTree code,
from the last video, as your starting point.

00:01:43.200 --> 00:01:47.280
That will be my own approach.
Here's a hint, instead of the

00:01:47.280 --> 00:01:50.040
map value being a Long, I'll
be making that a nested Map.

00:01:51.000 --> 00:01:54.300
But if you're feeling more adventurous,
and want to see if you can figure out a

00:01:54.300 --> 00:01:59.640
way to use one of the streaming methods, go ahead.
This would be a great learning exercise for you.

00:02:00.540 --> 00:02:03.600
Or, you may want to try using
newDirectoryStream in a recursive way.

00:02:04.680 --> 00:02:07.860
You should test your code first,
on the current working directory,

00:02:07.860 --> 00:02:12.780
and then on some larger directory, to see how
well it performs with a much greater set of data.

00:02:13.680 --> 00:02:16.620
That's the challenge, and I want you
to try to have some fun with this.

00:02:17.460 --> 00:02:20.220
Pause the video now, and go
away and give that a try,

00:02:20.220 --> 00:02:22.740
and come back when you're ready
to walk through my solution.

00:02:26.880 --> 00:02:30.600
Ok, so how'd you get on?
Were you able to gather

00:02:30.600 --> 00:02:34.500
this information up, for the current
directory's sub folders, and so on?

00:02:35.400 --> 00:02:37.860
Let's walk through this
together, and see what we can do.

00:02:38.820 --> 00:02:41.640
I have the project up from
the last video, FileWalker.

00:02:42.420 --> 00:02:46.080
The first thing I'll do is copy the Main
class and paste that in the same package,

00:02:46.080 --> 00:02:47.340
renaming it to Challenge.

00:02:56.340 --> 00:02:59.520
In the main method, I'll change the
path back to the current working

00:02:59.520 --> 00:03:06.060
directory, by changing the two dots to one.
I'll change my depth, to include all directories.

00:03:06.960 --> 00:03:10.860
That means, I'll change the argument in the
constructor of the StatsVisitor instance,

00:03:10.860 --> 00:03:13.140
from one, to Integer dot MAX VALUE.

00:03:15.360 --> 00:03:18.300
Everything else here, can stay
the same in the main method.

00:03:19.080 --> 00:03:21.780
Next, I'm going to look at
the nested StatsVisitor class.

00:03:22.920 --> 00:03:26.580
I'll be changing the type of the
field, the map, folder Sizes.

00:03:27.600 --> 00:03:30.600
I'll change Long to be a map
instead, keyed by a String,

00:03:30.600 --> 00:03:35.940
and the value will be long in this nested map.
This map is going to hold my file size summary

00:03:35.940 --> 00:03:39.480
in bytes, my count of all files,
and my count of all folders.

00:03:40.380 --> 00:03:45.360
Making this change, gives me compiler errors,
everywhere this code is referencing that map.

00:03:46.260 --> 00:03:49.680
Before I address those issues,
I'll set up a couple of constants.

00:03:50.700 --> 00:03:55.560
These will be the keys into this map.
I'll make all of these private, static,

00:03:55.560 --> 00:04:01.140
final, string. The first will be the key
for the count of directories or sub folders.

00:04:02.100 --> 00:04:06.720
File size is the accumulated file size,
so the sum of all files in the folders.

00:04:07.800 --> 00:04:10.333
File count is the number of files in the folders.

00:04:12.087 --> 00:04:14.520
First, I'll go to the preVisitDirectory method,

00:04:14.520 --> 00:04:17.460
since this is the first point
of contact, into the walk.

00:04:18.480 --> 00:04:22.980
You'll remember, I used this method, to
create a map entry for every single directory.

00:04:24.000 --> 00:04:28.163
I'm going to do something similar here,
but instead of putting 0L as the value,

00:04:28.163 --> 00:04:30.180
I'll change that to a new HashMap instance.

00:04:31.200 --> 00:04:35.460
Fortunately, the types can be inferred,
so I can just put angle brackets there.

00:04:36.360 --> 00:04:39.420
Next, I'll navigate up to the
visitFile directory method.

00:04:40.200 --> 00:04:42.600
I'll remove the folderSizes.merge statement.

00:04:43.500 --> 00:04:46.440
I'll replace that with the code to
populate the nested map instead.

00:04:47.400 --> 00:04:51.000
I'll start out by getting the parent
folder's map, for the current file's parent.

00:04:52.020 --> 00:04:56.460
It's possible that the current file's parent
might be the original path, and that's not part

00:04:56.460 --> 00:05:01.320
of my map, so I'll check for null here.
Remember, I'm purposely clearing the

00:05:01.320 --> 00:05:05.520
map at the start of each subfolder of the
original path, to give feedback to the user.

00:05:06.360 --> 00:05:10.620
It also doesn't chew up all the memory, if
I'm exercising this code on a large directory.

00:05:11.580 --> 00:05:15.300
File attributes are available as a method
argument, and I can get size from there.

00:05:16.140 --> 00:05:23.040
I'll merge the file size. If it's there, I'll just
put the file size in there. if this record isn't

00:05:23.040 --> 00:05:27.180
new, I need to add the file size to the current
data, and since that will be the new value,

00:05:27.180 --> 00:05:33.240
I can just use n in my expression. For the file
count, I'll do something similar, setting the

00:05:33.240 --> 00:05:37.771
value to 1L, if the record didn't exist, or adding
this value to the value in the map.

00:05:38.604 --> 00:05:43.980
This time,I'll use a method reference, with a method on
the Math class, so you can see an alternative.

00:05:45.360 --> 00:05:50.460
That's all I need to do when I'm visiting a file.
For good measure, I'll override the

00:05:50.460 --> 00:05:53.640
last method left that I haven't
implemented, on SimpleFileVisitor.

00:05:54.420 --> 00:05:56.460
I'll insert this after the visitFile method.

00:05:57.300 --> 00:06:00.600
Using IntelliJ's tools,
I'll pick visitFileFailed.

00:06:07.020 --> 00:06:10.440
As I did before, I'll click on
the super.visitFileFailed there,

00:06:10.440 --> 00:06:12.300
to bring up the code in the parent class.

00:06:13.500 --> 00:06:18.720
I'll just copy the first statement here, and paste
it in my method, instead of the return statement.

00:06:20.100 --> 00:06:23.400
This method has the path, and
an IO Exception as the argument.

00:06:24.360 --> 00:06:26.880
I'll check this second argument,
to see if it's not null.

00:06:27.720 --> 00:06:32.797
If not, I'll print the class name of the
exception, as well as the file name of the problem file.

00:06:33.652 --> 00:06:37.560
I'm printing the class name,
because many of the exceptions are named, like

00:06:37.560 --> 00:06:42.600
AccessDeniedException, and FileSystemLoopException
for example, and offer enough information,

00:06:42.600 --> 00:06:44.841
without a full stack trace.

00:06:45.740 --> 00:06:48.661
Finally, I don'twant to stop the walk, so I'll continue.

00:06:50.100 --> 00:06:53.947
Ok, so one thing I want to point
out at this point, is that my class,

00:06:53.947 --> 00:06:57.240
doesn't really need to be a subclass
of the SimpleFileVisitor class anymore.

00:06:58.260 --> 00:07:01.740
I've implemented custom implementations
for every method, so it doesn't really

00:07:01.740 --> 00:07:07.800
make sense to have SimpleFileVisitor as a parent.
I'll change my class declaration, and instead of

00:07:07.800 --> 00:07:12.360
extends SimpleFileVisitor, I'll change that to
implements FileVisitor, with Path as the type.

00:07:13.380 --> 00:07:17.280
Ok, I need to change one more method,
and I can test this thing out.

00:07:18.120 --> 00:07:22.500
The postVisitDirectory method is the one that's
going to roll the data up, to the parent levels.

00:07:23.400 --> 00:07:25.740
I'll start by looking at the
else clause of this code.

00:07:26.700 --> 00:07:28.680
I'll remove the two statements that are here.

00:07:31.560 --> 00:07:37.560
First, I'll get the parent's map data again,
from the folder Sizes map, using dir.getParent().

00:07:38.460 --> 00:07:40.418
Next, I'll get the child's map.

00:07:41.931 --> 00:07:46.452
I'll set up some local variables, for the 3 fields I'll be adding to the parent's summary fields.

00:07:47.346 --> 00:07:49.700
 Here, I'll get the directory count from the map.

00:07:50.664 --> 00:07:56.220
I need to use the getOrDefault method, because this data may not
exist in the map, in the case where a directory,

00:07:56.220 --> 00:08:00.092
didn't have a sub folder in it, so I'll return
0L in that case.

00:08:00.903 --> 00:08:02.903
I'll do the same for file size.

00:08:04.740 --> 00:08:06.628
That's true for file count too.

00:08:09.193 --> 00:08:12.289
Next, I'll merge this data into the parent's mapped values.

00:08:13.200 --> 00:08:16.171
For folder count, I'll include an extra increment
by 1,

00:08:16.368 --> 00:08:19.661
so that the current directory, is added to the parent's summary.

00:08:20.534 --> 00:08:23.700
For the other two fields,
I'll just insert them if these entries don't

00:08:23.700 --> 00:08:26.068
exist, or add it to the existing value.

00:08:27.427 --> 00:08:29.514
Ok, so that's it for the else clause.

00:08:30.420 --> 00:08:34.800
Next, I want to change how this data gets
printed out, so I'll move up to the if clause.

00:08:35.820 --> 00:08:41.580
I'll remove the System.out.printf statement.
I'll do something similar, but first I want

00:08:41.580 --> 00:08:46.620
to set up a local variable for the size.
I can get size from entry being iterated on.

00:08:47.400 --> 00:08:51.240
If file size isn't in the nested
map, I'll return 0L as the size.

00:08:52.380 --> 00:08:57.720
This print statement will start like the previous
one, with an indent level, the path name, and the

00:08:57.720 --> 00:09:02.820
number of bytes, but I also want the number
of files and folders. Tabs will be based on

00:09:02.820 --> 00:09:08.760
the level, and I'll just print the last part of
the path name, and then size. Next I'll get the

00:09:08.760 --> 00:09:14.940
file count, again using getOrDefault. And the same
thing for dir count, or the count of sub folders.

00:09:16.320 --> 00:09:17.826
Ok, that's it.

00:09:18.703 --> 00:09:21.975
The code compiles and I should be able to run this for the current directory.

00:09:24.233 --> 00:09:27.412
Here, I see all my FileWalker project's folders listed,

00:09:27.412 --> 00:09:30.900
and the size, number of files
and number of folders I have in each.

00:09:31.920 --> 00:09:35.580
You can try this code on much larger
folders, but I'd recommend changing

00:09:35.580 --> 00:09:40.200
the print level (the integer you pass to the
stats visitor constructor) back to one or two.

00:09:41.220 --> 00:09:45.240
It takes a little while to run this on root
for example, if you do have access to root.

00:09:45.960 --> 00:09:48.480
You may get some access denied
exceptions along the way.

00:09:49.500 --> 00:09:52.200
Ok, so I hope you were able to
figure that out on your own.

00:09:53.040 --> 00:09:55.320
Did you challenge yourself
to try it some other way,

00:09:55.320 --> 00:09:59.160
maybe with a streaming method, or
recursive directory stream method?

00:10:00.000 --> 00:10:04.200
One thing that makes the walkFileTree method
kind of nice is, you can catch the exception

00:10:04.200 --> 00:10:07.920
and ignore it and keep running, which is
harder to do when you're working with streams.

00:10:08.940 --> 00:10:13.560
It's also frowned on, to have side effects
with functional programming, which streams are.

00:10:14.460 --> 00:10:18.660
I'll show you one example, that doesn't propagate
or roll up the data to the parent's level,

00:10:18.660 --> 00:10:23.940
but simply aggregates it, at the level you choose.
I'll create a new class in the

00:10:23.940 --> 00:10:27.960
dev dot lpa package, with a main
method, and call it ChallengeStreams.

00:10:34.140 --> 00:10:37.740
I'll start in the main method,
with a local variable, startingPath

00:10:37.740 --> 00:10:40.000
and this time, set that to two dots.

00:10:40.811 --> 00:10:42.811
I'll get the starting path's index count.

00:10:43.620 --> 00:10:49.260
All my directories will be relative to this.
Next, I need a try with resources statement,

00:10:49.260 --> 00:10:54.540
and here I'll use Files.walk, with the
startingPath, and Integer Max Value for depth.

00:10:55.500 --> 00:10:58.416
I'll need a catch clause, for IO Exceptions.

00:10:59.271 --> 00:11:01.271
I'll just print the stack trace of the error out.

00:11:03.960 --> 00:11:07.740
Now, I'll start my stream pipeline,
starting with my source paths.

00:11:08.750 --> 00:11:12.600
First I'll filter, and here I only
want to look at files, not directories.

00:11:13.560 --> 00:11:18.780
That's because, in this code, I'm only going to
sum up the file size, and get the file count,

00:11:18.780 --> 00:11:21.331
with built-in features of the stream pipeline.

00:11:22.186 --> 00:11:25.216
I'll use the collect terminal operation,
with grouping by.

00:11:26.110 --> 00:11:28.440
 Here I want to
group by the first relative path name,

00:11:28.440 --> 00:11:32.580
so I'm going to use sub path, with the index
of the original path's number of parts,

00:11:32.580 --> 00:11:36.960
and I'll just add one to that, so this folder
will just have a single part of the path name.

00:11:38.112 --> 00:11:42.060
In other words, my data will be grouped
by the first level of sub folders.

00:11:43.020 --> 00:11:47.580
Next, I'll call summarizingLong, which gives
me summary statistics on the field I want.

00:11:48.480 --> 00:11:55.000
If I use file size, this data will give me both
the sum, the count, and other stats like average, and so on.

00:11:55.935 --> 00:11:59.520
My lambda expression will
return the size, using Files.size.

00:12:00.600 --> 00:12:05.040
Unfortunately, this throws an IO Exception
so I need a try catch block around the call,

00:12:05.040 --> 00:12:08.783
which is pretty ugly here. I'll return the size.

00:12:13.260 --> 00:12:17.880
I can append a for Each to the result, a
map, with paths and LongSummaryStatistics.

00:12:18.840 --> 00:12:22.620
I'll print this data out, much like
I did before, without indents though.

00:12:23.400 --> 00:12:25.560
I'll print the sum on that result, and the count.

00:12:26.880 --> 00:12:29.880
Ok, that's it.
I'll run that.

00:12:31.980 --> 00:12:36.360
I'll get my intellij project folders printed
out, with the size and number of files.

00:12:37.380 --> 00:12:41.880
That was quick work.
Again, it's not rolling the data up at every

00:12:41.880 --> 00:12:46.740
single level, but only by the level I grouped
by, and this code ignores sub folder counts.

00:12:47.700 --> 00:12:49.380
If this is the data you care about,

00:12:49.380 --> 00:12:52.260
this is a pretty quick way to get
that first level of information.

00:12:53.520 --> 00:12:56.760
Notice these aren't ordered, because
the resulting map is a hash map.

00:12:57.660 --> 00:13:01.260
I can very quickly change that, by
piping the map entries to a stream.

00:13:02.280 --> 00:13:04.980
I'll call entrySet on the
first stream's resulting map.

00:13:06.000 --> 00:13:11.220
I'll follow that, with a call to a stream
method. I'll sort, using Comparator.comparing,

00:13:12.120 --> 00:13:16.560
passing it the entry, and using
getKey (or the path) to sort on.

00:13:18.060 --> 00:13:22.380
I have to change my for each now, and pass
it the entry, rather than the key and value.

00:13:30.720 --> 00:13:31.809
Running that,

00:13:33.716 --> 00:13:35.716
I'll now get my folders printed in order.

00:13:38.220 --> 00:13:42.060
I can clean this stream pipeline up a
little bit, where this try catch surrounds

00:13:42.060 --> 00:13:45.300
the code to get the size.
I'll remove all of this.

00:13:48.240 --> 00:13:50.340
I'll replace that with a
different lambda expression.

00:13:51.360 --> 00:13:56.340
In this case, I'll use a method on path, called
toFile, which will give me a file instance.

00:13:58.320 --> 00:14:02.460
That has length as a field and I can get
that, which gives me the same data as size.

00:14:03.600 --> 00:14:08.340
Using this method is a bit less performant, but
if you're not doing anything too intense, this is

00:14:08.340 --> 00:14:13.800
one way to have slightly easier to read code.
You could also wrap the call to Files.size

00:14:13.800 --> 00:14:17.400
in a wrapper method, that catches the
exception, and call that method here.

00:14:19.320 --> 00:14:21.240
Running this code gives me the same result.

00:14:24.600 --> 00:14:28.380
What's nice about this second stream in the
pipeline, is that I could continue to hone

00:14:28.380 --> 00:14:32.880
and filter these summary results.
For example, I'll filter out all

00:14:32.880 --> 00:14:38.280
folders that are at least 50 kilobytes.
I'll add a filter, and filter by the sum &amp;gt;

00:14:38.280 --> 00:14:41.580
50 thousand bytes.
Running this code,

00:14:43.740 --> 00:14:46.800
I only have a couple of project
folders that meet that criteria.

00:14:47.640 --> 00:14:51.480
I could run this code with a filter on
a billion bytes, to look for the largest

00:14:51.480 --> 00:14:56.160
folders in a directory, for example.
Depending on what you might be doing,

00:14:56.160 --> 00:14:59.280
one of the stream methods, might
easily give you what you need.

00:15:00.300 --> 00:15:03.300
If you need to roll up the
data, in a hierarchical way,

00:15:03.300 --> 00:15:06.780
the walkFileTree is probably a better
solution for that kind of thing.

00:15:07.740 --> 00:15:11.760
Now that you're pretty adept at exploring
a directory tree, it's time to move on,

00:15:11.760 --> 00:15:15.960
and focus on reading data from files.
Let's move on.
